import streamlit as st
import requests
from typing import List
import os
from dotenv import load_dotenv
from dataclasses import dataclass
from PIL import Image

@dataclass
class Message:
    content: str
    type: str

def get_completion(message: str, history: List[Message]) -> dict:
    """Send request and get completion."""
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ N —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
    MAX_HISTORY_LENGTH = 10
    filtered_history = history[-MAX_HISTORY_LENGTH:] if len(history) > MAX_HISTORY_LENGTH else history
    
    print("\n–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ –±—ç–∫–µ–Ω–¥:")
    print(f"–°–æ–æ–±—â–µ–Ω–∏–µ: {message}")
    print(f"–ò—Å—Ç–æ—Ä–∏—è (–ø–æ—Å–ª–µ–¥–Ω–∏–µ {len(filtered_history)} —Å–æ–æ–±—â–µ–Ω–∏–π):")
    for msg in filtered_history:
        print(f"- {msg.type}: {msg.content[:100]}...")
    
    response = requests.post(
        "http://localhost:8000/completion",
        json={
            "message": message,
            "history": [{"content": msg.content, "type": msg.type} for msg in filtered_history]
        }
    )
    return response.json()

def get_voice(text: str, voice: str = "zabelin") -> bytes:
    """Get voice synthesis from TTS service."""
    response = requests.get(
        os.getenv("SK_API_EP"),
        params={"text": text, "voice": voice}
    )
    return response.content

def main():
    # Setup page
    logo = Image.open('./images/logo.png')
    resized_logo = logo.resize((100, 100))
    st.set_page_config(page_title="–ó–∞–±–µ–ª–∏–Ω —á–∞—Ç-–±–æ—Ç", page_icon="")
    st.image(resized_logo)
    st.title('üìñ –ó–∞–±–µ–ª–∏–Ω —á–∞—Ç-–±–æ—Ç')
    
    # Initialize session state with additional parameters
    if "messages" not in st.session_state:
        st.session_state.messages = [Message(content="–ü—Ä–∏–≤–µ—Ç, —è –ù–∏–∫–∏—Ç–∞ –ó–∞–±–µ–ª–∏–Ω! –ß–µ–º –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å?", type="ai")]
    if "conversation_started" not in st.session_state:
        st.session_state.conversation_started = False
    
    # Add conversation management UI
    with st.sidebar:
        if st.button("–ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥"):
            st.session_state.messages = [Message(content="–ü—Ä–∏–≤–µ—Ç, —è –ù–∏–∫–∏—Ç–∞ –ó–∞–±–µ–ª–∏–Ω! –ß–µ–º –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å?", type="ai")]
            st.session_state.conversation_started = False
            st.rerun()
    
    # Display messages
    for msg in st.session_state.messages:
        st.chat_message(msg.type).write(msg.content)
    
    # Handle user input
    if prompt := st.chat_input():
        # Add user message
        st.chat_message("human").write(prompt)
        st.session_state.messages.append(Message(content=prompt, type="human"))
        
        # Get completion from backend
        response = get_completion(prompt, st.session_state.messages)
        
        # Display AI response
        st.chat_message("ai").write(response["response"])
        st.session_state.messages.append(Message(content=response["response"], type="ai"))
        
        # Handle voice synthesis
        reply_audio = get_voice(response["response"])
        question_audio = get_voice(prompt)
        
        # Create audio players
        col1, col2 = st.columns(2)
        with col1:
            st.write("–û–∑–≤—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç:")
            st.audio(reply_audio, format="audio/mpeg", loop=False)
        with col2:
            st.write("–û–∑–≤—É—á–∏—Ç—å –≤–æ–ø—Ä–æ—Å:")
            st.audio(question_audio, format="audio/mpeg", loop=False)
        
        # Display sources
        for i, source in enumerate(response["context_sources"], 1):
            with st.expander(f"**–ò—Å—Ç–æ—á–Ω–∏–∫ N{i}:** [{source['source']}]"):
                st.write(source["content"])

if __name__ == "__main__":
    try:
        load_dotenv()
        main()
    except Exception as e:
        st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")